# Speech Coach API

Сервис для анализа качества публичной речи по загружаемым видеофайлам. Извлекает аудиодорожку, выполняет локальное распознавание речи с помощью Whisper через faster-whisper, анализирует ключевые метрики и предоставляет структурированные рекомендации с возможностью расширенного AI-анализа через GigaChat API.

## Возможности

✅ **Базовый анализ** - основные метрики речи (темп, слова-паразиты, паузы)  
✅ **Детализированный анализ** - полные тайминги слов, пауз и фраз с визуализацией  
✅ **Расширенный AI-анализ** - интеграция с GigaChat для глубокой оценки выступления  
✅ **Мониторинг** - метрики системы и производительности  

## Быстрый старт

```bash
# Клонирование репозитория
git clone https://github.com/xXxDanya2007xXx/speech-coach.git
cd speech-coach

# Создание виртуального окружения
python -m venv .venv

# Активация окружения
# Linux/macOS:
source .venv/bin/activate
# Windows (PowerShell):
.\\.venv\\Scripts\\Activate.ps1
# Windows (CMD):
.venv\\Scripts\\activate

# Установка зависимостей
pip install -r requirements.txt

# Настройка конфигурации
cp .env.example .env

# Создание необходимых директорий
mkdir -p logs cache

# Запуск сервера разработки
uvicorn app.main:app --reload

## Тесты

Для локальной проверки запустите (рекомендуется использовать виртуальное окружение):

```bash
pip install -r requirements-ci.txt
pytest -q
```

В CI используется workflow `.github/workflows/ci.yml`, который устанавливает минимальные зависимости из `requirements-ci.txt` и запускает `pytest` на push/PR.
```

После запуска API будет доступен по адресу `http://127.0.0.1:8000`. Интерактивная документация (Swagger UI) доступна по пути `/docs`.

## Использование API

### Базовый анализ (рекомендуется для быстрой проверки)

```bash
curl -X POST "http://127.0.0.1:8000/api/v1/analyze" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@path/to/your/video.mp4"
```

### Детализированный анализ с таймингами

```bash
curl -X POST "http://127.0.0.1:8000/api/v1/analyze/detailed" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@path/to/your/video.mp4"
```

**Возвращает:**
- Тайминги каждого слова с точными временами
- Слова-паразиты с позициями и контекстом
- Паузы с типом, длительностью и контекстом
- Фразы с метриками сложности и темпа
- Данные для визуализации активности речи

### Получение метрик системы

```bash
curl "http://127.0.0.1:8000/api/v1/metrics/system"
```

### Проверка здоровья сервиса

```bash
curl "http://127.0.0.1:8000/health"
```

**Поддерживаемые форматы видео:** MP4, MOV, AVI, MKV, WEBM, FLV, WMV, M4V  
**Максимальный размер файла:** 100 MB

## Конфигурация

Ключевые настройки определяются в файле `.env`:

```env
# Обязательные настройки
FFMPEG_PATH=ffmpeg
WHISPER_MODEL=small
WHISPER_DEVICE=cpu
MAX_FILE_SIZE_MB=100

# Опциональные настройки для GigaChat API
GIGACHAT_ENABLED=false
# GIGACHAT_API_KEY=your_authorization_key_here

# Настройки логирования
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Настройки кеширования
CACHE_ENABLED=true
CACHE_TTL=3600
```

Полный список доступных параметров представлен в файле [.env.example](.env.example).

Дополнительно вы можете управлять параметрами детекции пауз и VAD:

- `MIN_PAUSE_GAP_SEC` — минимальный разрыв между словами, считающийся паузой (сек)
- `LONG_PAUSE_SEC` — порог для длинной паузы (сек)
- `SILENCE_FACTOR` — отношение порога тишины к медиане RMS речи
- `USE_WEBRTC_VAD` — включить webrtcvad (рекомендуется для быстрого VAD)
- `USE_PYANNOTE_VAD` — включить pyannote.audio (подойдет для более точной детекции, требует PyTorch)
- `FILLER_CLUSTER_GAP_SEC` — окно, в пределах которого слова-паразиты считаются кластером
- `LLM_FILLERS_ENABLED` — включить LLM для контекстной классификации слов-паразитов через GigaChat (по умолчанию: True)

Если вы включаете `USE_PYANNOTE_VAD`, убедитесь, что установлены `torch` и `pyannote.audio`. Для production-серверов pyannote рекомендуется использовать отдельный worker-узел из-за расходов памяти.

## Анализируемые метрики

### Базовые метрики
- **Темп речи** – количество слов в минуту, рассчитанное по чистому времени говорения
- **Слова-паразиты** – частота использования заполнителей пауз на русском и английском языках
- **Паузы** – количество, средняя и максимальная длительность, распределение
- **Структура фраз** – средняя длина фразы, классификация по длине, вариативность ритма
- **Коэффициент говорения** – доля времени, в течение которого спикер говорит

### Расширенные метрики (с таймингами)
- **Точные тайминги слов** – время начала и окончания каждого слова
  - **Формат:** все временные метки (start/end/timestamp/duration) приведены с точностью до 3 знаков после запятой (миллисекунды)
Дополнительно: `TimedFillerWord` теперь включает поле `duration` (в секундах) и опциональные поля `context_score` и `is_context_filler`, если включён LLM-клиент.

- **Контекстные паузы** – паузы с информацией о соседних словах
- **Эмоциональные пики** – моменты с повышенной эмоциональностью речи
- **Ритмические паттерны** – закономерности в темпе и паузах
- **Проблемные моменты** – выделенные проблемные участки речи с рекомендациями

## Архитектура системы

Основные компоненты сервиса:

1. **Pipeline** – координирует процесс обработки от загрузки видео до формирования результата
2. **Audio Extractor** – извлекает аудиодорожку с помощью FFmpeg
3. **Transcriber** – выполняет распознавание речи с использованием модели Whisper (с таймингами слов)
4. **Analyzer** – рассчитывает базовые метрики качества речи
5. **Advanced Analyzer** – выполняет детализированный анализ с полными таймингами
6. **GigaChat Client** – обеспечивает интеграцию с GigaChat API для расширенного AI-анализа (опционально)

## Устранение неполадок

### Ошибка "FFmpeg not found"
- Убедитесь, что FFmpeg установлен и доступен в PATH
- Проверьте путь в настройке `FFMPEG_PATH`

### Длительная загрузка при первом запуске
- Сервис загружает модель Whisper при первом использовании (несколько сотен МБ)
- Для ускорения используйте меньшую модель: `WHISPER_MODEL=tiny` или `WHISPER_MODEL=base`

### Ошибка памяти при анализе больших файлов
- Уменьшите значение `MAX_FILE_SIZE_MB`
- Используйте модель меньшего размера
- Увеличьте объем оперативной памяти

### Ошибки GigaChat API
- Убедитесь, что `GIGACHAT_ENABLED=true` и установлен `GIGACHAT_API_KEY`
- Проверьте доступность GigaChat API
- При ошибках 429 (rate limit) дождитесь снятия ограничений

## Структура проекта

Примечание: `app/models/timed_models.py` содержит канонические модели с детализированными таймингами. Файл `app/models/timed_analysis.py` содержит удобные ре-экспорты и совместимые сокращённые модели для обратной совместимости.

```
speech-coach/
├── app/
│   ├── api/routes/           # Маршруты FastAPI
│   │   ├── analysis.py       # Эндпоинты анализа
│   │   ├── health.py         # Проверка здоровья
│   │   └── metrics.py        # Метрики системы
│   ├── core/                 # Конфигурация и утилиты
│   │   ├── config.py         # Настройки приложения
│   │   ├── exceptions.py     # Кастомные исключения
│   │   ├── lifespan.py       # Управление жизненным циклом
│   │   ├── logging_config.py # Конфигурация логирования
│   │   └── validators.py     # Валидаторы данных
│   ├── models/               # Pydantic модели
│   │   ├── analysis.py       # Модели базового анализа
│   │   ├── timed_models.py   # Модели с таймингами
│   │   ├── transcript.py     # Модели транскрипта
│   │   └── gigachat.py       # Модели GigaChat
│   ├── services/             # Бизнес-логика
│   │   ├── audio_extractor.py # Извлечение аудио
│   │   ├── transcriber.py    # Распознавание речи
│   │   ├── analyzer.py       # Базовый анализатор
│   │   ├── analyzer_advanced.py # Расширенный анализатор
│   │   ├── pipeline.py       # Основной пайплайн
│   │   ├── pipeline_advanced.py # Расширенный пайплайн
│   │   ├── gigachat.py       # Клиент GigaChat
│   │   ├── cache.py          # Кеширование
│   │   └── metrics_collector.py # Сбор метрик
│   └── main.py               # Точка входа FastAPI
├── .env.example              # Пример файла конфигурации
├── requirements.txt          # Зависимости Python
├── LICENSE                   # Лицензия MIT
└── README.md                 # Документация
```

## Лицензия

Проект распространяется под лицензией MIT. Полный текст лицензии доступен в файле [LICENSE](LICENSE).

## Поддержка

При возникновении проблем:
1. Проверьте логи в `logs/app.log`
2. Убедитесь, что все зависимости установлены
3. Проверьте настройки в `.env`
4. Откройте issue на GitHub с описанием проблемы
