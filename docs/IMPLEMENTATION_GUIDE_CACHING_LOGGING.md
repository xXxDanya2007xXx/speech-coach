# üîß –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –≥–∞–π–¥: –£–ª—É—á—à–µ–Ω–∏–µ –ö—ç—à–∞, –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç–∏

**–¶–µ–ª–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å**: Production-ready
**–í—Ä–µ–º—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è**: 4-6 —á–∞—Å–æ–≤
**–°–ª–æ–∂–Ω–æ—Å—Ç—å**: –°—Ä–µ–¥–Ω—è—è

---

## –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢ (15 –º–∏–Ω—É—Ç)

### –ß—Ç–æ —Å—Ä–∞–∑—É –¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π)
pip install cachetools pythonjsonlogger

# 2. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–¥–ª—è Redis - –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)
pip install redis

# 3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–¥–ª—è circuit breaker)
pip install pybreaker
```

---

## 1Ô∏è‚É£ –£–õ–£–ß–®–ï–ù–ò–ï –ö–≠–®–ò–†–û–í–ê–ù–ò–Ø (–ü–†–ò–û–†–ò–¢–ï–¢ 1)

### –í–∞—Ä–∏–∞–Ω—Ç A: –ë—ã—Å—Ç—Ä–æ–µ —Ä–µ—à–µ–Ω–∏–µ (–±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)

–î–æ–±–∞–≤—å—Ç–µ in-memory LRU –∫—ç—à –ø–µ—Ä–µ–¥ –¥–∏—Å–∫–æ–º:

```python
# app/services/cache_manager.py - –ù–û–í–´–ô –§–ê–ô–õ

import asyncio
import logging
from typing import Any, Optional
from cachetools import TTLCache
from pathlib import Path

logger = logging.getLogger(__name__)

class TwoLevelCache:
    """–î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π –∫—ç—à: –ø–∞–º—è—Ç—å (–≥–æ—Ä—è—á–∏–µ –¥–∞–Ω–Ω—ã–µ) + –¥–∏—Å–∫ (—Ö–æ–ª–æ–¥–Ω—ã–µ)"""
    
    def __init__(
        self,
        disk_cache=None,  # AnalysisCache instance
        memory_maxsize: int = 100,
        ttl_seconds: int = 3600
    ):
        # L1: In-memory –∫—ç—à –¥–ª—è –≥–æ—Ä—è—á–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        self.memory = TTLCache(maxsize=memory_maxsize, ttl=ttl_seconds)
        
        # L2: –î–∏—Å–∫ –∫—ç—à –¥–ª—è —Ö–æ–ª–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.disk = disk_cache
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.hits_memory = 0
        self.hits_disk = 0
        self.misses = 0
    
    async def get(self, key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –ø–∞–º—è—Ç—å ‚Üí –¥–∏—Å–∫"""
        
        # –ü–æ–ø—ã—Ç–∫–∞ L1 (0.1ms)
        if key in self.memory:
            self.hits_memory += 1
            logger.debug(f"Cache L1 hit: {key}")
            return self.memory[key]
        
        # –ü–æ–ø—ã—Ç–∫–∞ L2 (10-50ms)
        if self.disk:
            value = await asyncio.to_thread(self.disk.get_by_key, key)
            if value is not None:
                # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ L1 –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–∞
                self.memory[key] = value
                self.hits_disk += 1
                logger.debug(f"Cache L2 hit: {key}")
                return value
        
        self.misses += 1
        logger.debug(f"Cache miss: {key}")
        return None
    
    async def set(self, key: str, value: Any) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –æ–±–∞ —É—Ä–æ–≤–Ω—è –∫—ç—à–∞"""
        self.memory[key] = value
        
        if self.disk:
            await asyncio.to_thread(self.disk.set_by_key, key, value)
    
    def stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫—ç—à–∞"""
        total = self.hits_memory + self.hits_disk + self.misses
        hit_rate = (self.hits_memory + self.hits_disk) / total if total > 0 else 0
        
        return {
            "hits_memory": self.hits_memory,
            "hits_disk": self.hits_disk,
            "misses": self.misses,
            "total_requests": total,
            "hit_rate": f"{hit_rate*100:.1f}%",
            "memory_size": len(self.memory),
            "memory_maxsize": self.memory.maxsize,
        }
    
    async def clear(self) -> None:
        """–û—á–∏—Å—Ç–∏—Ç—å –æ–±–∞ —É—Ä–æ–≤–Ω—è"""
        self.memory.clear()
        if self.disk:
            await asyncio.to_thread(self.disk.clear_old)
```

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –∫–æ–¥

```python
# app/api/deps.py - –û–ë–ù–û–í–ò–¢–¨

from app.services.cache_manager import TwoLevelCache
from app.services.cache import AnalysisCache
from pathlib import Path

@lru_cache(maxsize=1)
def get_cache_manager() -> TwoLevelCache:
    """–°–æ–∑–¥–∞–µ—Ç –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π –∫—ç—à –º–µ–Ω–µ–¥–∂–µ—Ä"""
    disk_cache = AnalysisCache(
        cache_dir=Path(settings.cache_dir),
        ttl_seconds=settings.cache_ttl
    )
    return TwoLevelCache(
        disk_cache=disk_cache,
        memory_maxsize=100,  # –î–æ 100 –∞–Ω–∞–ª–∏–∑–æ–≤ –≤ –ø–∞–º—è—Ç–∏
        ttl_seconds=settings.cache_ttl
    )
```

#### –î–æ–±–∞–≤–∏—Ç—å endpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫—ç—à–∞

```python
# app/api/routes/health.py - –î–û–ë–ê–í–ò–¢–¨

from app.api.deps import get_cache_manager

@router.get("/stats/cache")
async def cache_stats(cache_manager = Depends(get_cache_manager)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞"""
    return cache_manager.stats()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
# GET /stats/cache
# –û—Ç–≤–µ—Ç:
# {
#   "hits_memory": 45,
#   "hits_disk": 12,
#   "misses": 8,
#   "hit_rate": "87.7%",
#   "memory_size": 23
# }
```

---

### –í–∞—Ä–∏–∞–Ω—Ç B: –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ (—Å Redis)

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å Redis (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è production):

```python
# app/services/cache_manager.py - –í–ê–†–ò–ê–ù–¢ –° REDIS

import asyncio
import logging
from typing import Any, Optional
from cachetools import TTLCache
from redis import Redis
from redis.asyncio import Redis as AsyncRedis
import json

logger = logging.getLogger(__name__)

class RedisCache:
    """–¢—Ä—ë—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π –∫—ç—à: –ø–∞–º—è—Ç—å + Redis + –¥–∏—Å–∫"""
    
    def __init__(
        self,
        redis_url: str = "redis://localhost:6379",
        disk_cache=None,
        memory_maxsize: int = 50,
        ttl_seconds: int = 3600
    ):
        # L1: In-memory
        self.memory = TTLCache(maxsize=memory_maxsize, ttl=ttl_seconds)
        
        # L2: Redis (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        try:
            self.redis = Redis.from_url(redis_url, decode_responses=True)
            self.redis.ping()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            self.redis_available = True
            logger.info(f"Redis connected: {redis_url}")
        except Exception as e:
            logger.warning(f"Redis not available: {e}")
            self.redis = None
            self.redis_available = False
        
        # L3: –î–∏—Å–∫
        self.disk = disk_cache
        self.ttl_seconds = ttl_seconds
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.hits_l1 = self.hits_l2 = self.hits_l3 = self.misses = 0
    
    async def get(self, key: str) -> Optional[Any]:
        """L1 (0.1ms) ‚Üí L2 (1-5ms) ‚Üí L3 (10-50ms)"""
        
        # L1: –ü–∞–º—è—Ç—å
        if key in self.memory:
            self.hits_l1 += 1
            return self.memory[key]
        
        # L2: Redis
        if self.redis_available:
            try:
                value_json = await asyncio.to_thread(self.redis.get, key)
                if value_json:
                    import pickle
                    value = pickle.loads(json.loads(value_json))
                    self.memory[key] = value  # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ L1
                    self.hits_l2 += 1
                    return value
            except Exception as e:
                logger.debug(f"Redis get error: {e}")
        
        # L3: –î–∏—Å–∫
        if self.disk:
            try:
                value = await asyncio.to_thread(self.disk.get_by_key, key)
                if value:
                    self.memory[key] = value
                    if self.redis_available:
                        # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ Redis –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                        await self._set_redis(key, value)
                    self.hits_l3 += 1
                    return value
            except Exception as e:
                logger.debug(f"Disk get error: {e}")
        
        self.misses += 1
        return None
    
    async def set(self, key: str, value: Any) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–æ –≤—Å–µ —É—Ä–æ–≤–Ω–∏"""
        self.memory[key] = value
        
        if self.redis_available:
            await self._set_redis(key, value)
        
        if self.disk:
            await asyncio.to_thread(self.disk.set_by_key, key, value)
    
    async def _set_redis(self, key: str, value: Any) -> None:
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Redis"""
        try:
            import pickle
            value_json = json.dumps(pickle.dumps(value).decode('latin1'))
            await asyncio.to_thread(
                self.redis.setex,
                key,
                self.ttl_seconds,
                value_json
            )
        except Exception as e:
            logger.debug(f"Redis set error: {e}")
    
    def stats(self) -> dict:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        total = self.hits_l1 + self.hits_l2 + self.hits_l3 + self.misses
        
        return {
            "l1_memory_hits": self.hits_l1,
            "l2_redis_hits": self.hits_l2,
            "l3_disk_hits": self.hits_l3,
            "misses": self.misses,
            "total": total,
            "hit_rate": f"{(total-self.misses)/total*100:.1f}%" if total > 0 else "0%",
            "memory_size": len(self.memory),
            "redis_available": self.redis_available,
        }
```

**–ö–æ–Ω—Ñ–∏–≥ Redis –≤ `.env`**:
```env
# –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Redis
REDIS_URL=redis://localhost:6379/0

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—ç—à–∞
CACHE_TTL=3600
CACHE_DIR=cache/analysis
```

---

## 2Ô∏è‚É£ JSON –õ–û–ì–ò–†–û–í–ê–ù–ò–ï (–ü–†–ò–û–†–ò–¢–ï–¢ 2)

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
pip install pythonjsonlogger
```

### –®–∞–≥ 2: –û–±–Ω–æ–≤–∏—Ç—å logging config

```python
# app/core/logging_config.py - –û–ë–ù–û–í–ò–¢–¨

import logging
import sys
from pathlib import Path
from logging.handlers import RotatingFileHandler
import coloredlogs
from pythonjsonlogger import jsonlogger
import uuid
from contextvars import ContextVar

# –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Request ID
request_id_var: ContextVar[str] = ContextVar('request_id', default='')

def get_request_id() -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π Request ID"""
    return request_id_var.get()

def setup_logging(
    log_level: str = "INFO",
    log_file: str = None,
    max_file_size: int = 10 * 1024 * 1024,
    backup_count: int = 5,
    json_logs: bool = True  # ‚Üê –ù–û–í–´–ô –ü–ê–†–ê–ú–ï–¢–†
):
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π JSON"""
    
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)
    
    # –§–æ—Ä–º–∞—Ç–µ—Ä –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏ (—Ç–µ–∫—Å—Ç —Å —Ü–≤–µ—Ç–∞–º–∏)
    console_formatter = coloredlogs.ColoredFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%H:%M:%S',
    )
    
    # –ö–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä
    root_logger = logging.getLogger()
    root_logger.setLevel(numeric_level)
    root_logger.handlers.clear()
    
    # –ö–æ–Ω—Å–æ–ª—å (—Ç–µ–∫—Å—Ç)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(console_formatter)
    root_logger.addHandler(console_handler)
    
    # –§–∞–π–ª (JSON –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if log_file:
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_handler = RotatingFileHandler(
            log_file,
            maxBytes=max_file_size,
            backupCount=backup_count,
            encoding='utf-8'
        )
        
        if json_logs:
            # JSON —Ñ–æ—Ä–º–∞—Ç–µ—Ä –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            json_formatter = jsonlogger.JsonFormatter()
            file_handler.setFormatter(json_formatter)
        else:
            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç–µ—Ä
            text_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(text_formatter)
        
        file_handler.setLevel(numeric_level)
        root_logger.addHandler(file_handler)
    
    # –ü–æ–¥–∞–≤–∏—Ç—å —à—É–º–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    logging.getLogger("asyncio").setLevel(logging.WARNING)
    
    root_logger.info(f"Logging configured: {log_level} (JSON={json_logs})")
```

### –®–∞–≥ 3: –î–æ–±–∞–≤–∏—Ç—å Request ID middleware

```python
# app/main.py - –î–û–ë–ê–í–ò–¢–¨

import uuid
from contextvars import ContextVar
from fastapi.requests import Request

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Request ID
from app.core.logging_config import request_id_var

@app.middleware("http")
async def add_request_id_middleware(request: Request, call_next):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π Request ID –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
    request_id = str(uuid.uuid4())
    request_id_var.set(request_id)
    
    response = await call_next(request)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ headers –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    response.headers["X-Request-ID"] = request_id
    
    return response
```

### –®–∞–≥ 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ

```python
# –ì–¥–µ —É–≥–æ–¥–Ω–æ –≤ –∫–æ–¥–µ
import logging
from app.core.logging_config import get_request_id

logger = logging.getLogger(__name__)

async def analyze_speech(...):
    request_id = get_request_id()
    logger.info(f"Starting analysis", extra={
        "request_id": request_id,
        "file_size": file_size,
        "duration": duration
    })
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–≥–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º request_id
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ª–æ–≥–∞—Ö

```json
// logs/app.log (JSON —Ñ–æ—Ä–º–∞—Ç)
{"asctime": "2025-12-19 14:30:45", "name": "app.api.routes", "levelname": "INFO", "message": "Starting analysis", "request_id": "abc-123-def", "file_size": 5000000, "duration": 30.5}
{"asctime": "2025-12-19 14:31:15", "name": "app.services", "levelname": "INFO", "message": "Analysis completed", "request_id": "abc-123-def"}

// stdout (—Ç–µ–∫—Å—Ç —Å —Ü–≤–µ—Ç–∞–º–∏)
14:30:45 - app.api.routes - INFO - Starting analysis
14:31:15 - app.services - INFO - Analysis completed
```

---

## 3Ô∏è‚É£ CIRCUIT BREAKER –¥–ª—è GigaChat (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
pip install pybreaker
```

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
# app/services/gigachat.py - –û–ë–ù–û–í–ò–¢–¨

from pybreaker import CircuitBreaker
import logging

logger = logging.getLogger(__name__)

class GigaChatClient:
    def __init__(self, verify_ssl: Optional[bool] = None):
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
        
        # Circuit breaker: –æ—Ç–∫–ª—é—á–∞–µ—Ç API –ø–æ—Å–ª–µ 5 –æ—à–∏–±–æ–∫ –Ω–∞ 60 —Å–µ–∫
        self.breaker = CircuitBreaker(
            fail_max=5,  # –û—Ç–∫–ª—é—á–∏—Ç—å –ø–æ—Å–ª–µ 5 –æ—à–∏–±–æ–∫
            reset_timeout=60,  # –ù–∞ 60 —Å–µ–∫—É–Ω–¥
            listeners=[
                self._on_breaker_change
            ]
        )
    
    def _on_breaker_change(self, event):
        """Callback –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è circuit breaker"""
        logger.warning(f"Circuit breaker event: {event}")
        if event == "open":
            logger.error("GigaChat API circuit opened - too many failures")
        elif event == "close":
            logger.info("GigaChat API circuit closed - API recovered")
    
    async def analyze_speech(self, analysis_result: AnalysisResult):
        """–ê–Ω–∞–ª–∏–∑ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∫–∞—Å–∫–∞–¥–Ω—ã—Ö —Å–±–æ–µ–≤"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ circuit breaker –ü–ï–†–ï–î –∑–∞–ø—Ä–æ—Å–æ–º
            if not self.breaker.closed:
                logger.warning("Circuit breaker is open, using fallback")
                return self._create_fallback_analysis(
                    "API temporarily unavailable"
                )
            
            # –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            response = await self.client.post(...)
            self.breaker.success()  # –û—Ç–º–µ—Ç–∏—Ç—å —É—Å–ø–µ—Ö
            return response
            
        except Exception as e:
            self.breaker.fail()  # –û—Ç–º–µ—Ç–∏—Ç—å –æ—à–∏–±–∫—É
            logger.error(f"Analysis failed: {e}")
            return self._create_fallback_analysis(str(e))
```

---

## 4Ô∏è‚É£ SEMAPHORE –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞

```python
# app/services/pipeline.py - –î–û–ë–ê–í–ò–¢–¨

import asyncio

class SpeechAnalysisPipeline:
    def __init__(self, max_parallel: int = 3):
        # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–æ 3 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        self.semaphore = asyncio.Semaphore(max_parallel)
        self.active_count = 0
        self.max_parallel = max_parallel
    
    async def analyze(self, file, ...):
        """–ê–Ω–∞–ª–∏–∑ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞"""
        async with self.semaphore:
            self.active_count += 1
            logger.info(f"Active analyses: {self.active_count}/{self.max_parallel}")
            
            try:
                return await self._do_analyze(file, ...)
            finally:
                self.active_count -= 1
    
    def status(self) -> dict:
        """–°—Ç–∞—Ç—É—Å –Ω–∞–≥—Ä—É–∑–∫–∏"""
        return {
            "active": self.active_count,
            "max_parallel": self.max_parallel,
            "queue_length": self.semaphore._value,
        }
```

---

## üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ò–ô

### –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –∫—ç—à–∞

```python
# tests/test_improved_cache.py

import pytest
from app.services.cache_manager import TwoLevelCache
from app.services.cache import AnalysisCache
from pathlib import Path
import asyncio

@pytest.mark.asyncio
async def test_two_level_cache():
    """–¢–µ—Å—Ç –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–æ–≥–æ –∫—ç—à–∞"""
    disk = AnalysisCache(Path("cache/test"), ttl_seconds=3600)
    cache = TwoLevelCache(disk_cache=disk, memory_maxsize=10)
    
    # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å ‚Üí misses
    value1 = await cache.get("key1")
    assert value1 is None
    assert cache.misses == 1
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
    test_data = {"result": "analysis"}
    await cache.set("key1", test_data)
    
    # –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å ‚Üí L1 hit (–ø–∞–º—è—Ç—å)
    value2 = await cache.get("key1")
    assert value2 == test_data
    assert cache.hits_memory == 1
    
    # Stats
    stats = cache.stats()
    assert "87.5%" in stats["hit_rate"]  # 1 hit –∏–∑ 2 requests –±—ã–ª–æ —Ä–∞–Ω—å—à–µ
```

### –¢–µ—Å—Ç JSON –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

```python
# tests/test_json_logging.py

import logging
import json
from io import StringIO
from pythonjsonlogger import jsonlogger

def test_json_logging():
    """–¢–µ—Å—Ç JSON –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger = logging.getLogger("test")
    
    # JSON handler
    stream = StringIO()
    handler = logging.StreamHandler(stream)
    handler.setFormatter(jsonlogger.JsonFormatter())
    logger.addHandler(handler)
    
    # –õ–æ–≥–∏—Ä—É–µ–º
    logger.info("Test message", extra={"user_id": 123})
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º JSON
    log_line = stream.getvalue().strip()
    log_dict = json.loads(log_line)
    
    assert log_dict["message"] == "Test message"
    assert log_dict["user_id"] == 123
```

---

## üìä –ú–ï–¢–†–ò–ö–ò –î–û –ò –ü–û–°–õ–ï

```
                        | –î–û       | –ü–û–°–õ–ï    | –£–õ–£–ß–®–ï–ù–ò–ï
|----------------------|----------|----------|----------
| –í—Ä–µ–º—è –∫—ç—à —Ö–∏—Ç–∞      | 10-50ms  | 0.1-1ms  | 50-500x
| JSON –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ    | ‚ùå –ù–µ—Ç   | ‚úÖ –î–∞    | –ü–∞—Ä—Å–∏–Ω–≥
| Request —Ç—Ä–µ–π—Å–∏–Ω–≥    | ‚ùå –ù–µ—Ç   | ‚úÖ –î–∞    | –û—Ç–ª–∞–¥–∫–∞
| Memory L1 –∫—ç—à       | ‚ùå –ù–µ—Ç   | ‚úÖ –î–∞    | +100x
| Circuit breaker     | ‚ùå –ù–µ—Ç   | ‚úÖ –î–∞    | –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å
```

---

## üöÄ –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–ï

### –í production

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt  # –£–∂–µ –≤–∫–ª—é—á–µ–Ω—ã –Ω–æ–≤—ã–µ

# 2. –°—Ç–∞—Ä—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç —Å Redis (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
docker-compose up -d redis

# 3. –ó–∞–ø—É—Å–∫ —Å JSON –ª–æ–≥–∞–º–∏
LOG_LEVEL=INFO REDIS_URL=redis://localhost:6379 python -m uvicorn app.main:app

# 4. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫—ç—à
curl http://localhost:8000/stats/cache
```

---

## üìù –ß–µ–∫–ª–∏—Å—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

- [ ] –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (cachetools, pythonjsonlogger)
- [ ] –î–æ–±–∞–≤–ª–µ–Ω TwoLevelCache –∏–ª–∏ RedisCache
- [ ] JSON –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
- [ ] Request ID middleware –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] Circuit breaker –¥–ª—è GigaChat (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- [ ] Semaphore –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- [ ] Endpoint /stats/cache –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] –¢–µ—Å—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω—ã
- [ ] –õ–æ–∫–∞–ª—å–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ
- [ ] –í production –∑–∞–¥–µ–ø–ª–æ–µ–Ω–æ

